{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEeMX03tWnj-"
   },
   "source": [
    "# RCNN - Regions with CNN\n",
    "In R-CNN instead of running classification on huge number of regions we pass the image through selective search and select first 2000 region proposal from the result and run classification on that. In this way instead of classifying huge number of regions we need to just classify first 2000 regions. This makes this algorithm fast compared to previous techniques of object detection.\n",
    "\n",
    "Steps :\n",
    "1. Pass the image through selective search and generate region proposal.\n",
    "2. Calculate IOU (intersection over union) on proposed region with ground truth data and add label to the proposed regions.\n",
    "3. Do transfer learning using the proposed regions with the labels.\n",
    "4. Pass the test image to selective search and then pass the first 2000 proposed regions from the trained model and predict the class of those regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31-U5eVSX98w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BURgjdn7WveY"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PrqqRF4DW2kZ"
   },
   "outputs": [],
   "source": [
    "#!unzip \"drive/My Drive/airplanes.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccCfdQJnWnkG"
   },
   "outputs": [],
   "source": [
    "import os,cv2,keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrwwlIP4WnkK"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vggmodel = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50j6bGFOWnkH"
   },
   "outputs": [],
   "source": [
    "image_path = \"airplanes/images/\"\n",
    "annot_path = \"airplanes/annotations/\"\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_l-fMDwPWnkH"
   },
   "outputs": [],
   "source": [
    "# Initializing selective search \n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocQqoXycWnkH"
   },
   "source": [
    "Intersection over Union is an evaluation metric used to measure the accuracy of an object detector on a particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72nUuPn9WnkH"
   },
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbEjKamfWnkI"
   },
   "source": [
    "1. set each image one by one as the base for selective search using code ss.setBaseImage(image).\n",
    "2. Initialising fast selective search and getting proposed regions using using code ss.switchToSelectiveSearchFast() and ssresults = ss.process().\n",
    "3. Iterating over all the first 2000 results passed by selective search and calculating IOU of the proposed region and annotated region using the user defined get_iou() function.\n",
    "4. To have good proportion between positives (airplane) = 1 and negatives (background) = 0, we will be considering 30 samples from each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN1WAVSAWnkI"
   },
   "outputs": [],
   "source": [
    "train_images=[]\n",
    "train_labels=[]\n",
    "for e,i in enumerate(os.listdir(image_path)):\n",
    "    try:\n",
    "        if i.startswith(\"airplane\"):\n",
    "            image_file = i.split(\".\")[0]+\".jpg\"\n",
    "            annot_file = i.split(\".\")[0]+\".csv\"\n",
    "            #print(e,image_file)\n",
    "            image = cv2.imread(os.path.join(image_path,image_file))\n",
    "            df = pd.read_csv(os.path.join(annot_path,annot_file))\n",
    "            gtvalues=[]\n",
    "            for row in df.iterrows():\n",
    "                x1 = int(row[1][0].split(\" \")[0])\n",
    "                y1 = int(row[1][0].split(\" \")[1])\n",
    "                x2 = int(row[1][0].split(\" \")[2])\n",
    "                y2 = int(row[1][0].split(\" \")[3])\n",
    "                gtvalues.append({\"x1\":x1,\"x2\":x2,\"y1\":y1,\"y2\":y2})\n",
    "            ss.setBaseImage(image)\n",
    "            ss.switchToSelectiveSearchFast()\n",
    "            ssresults = ss.process()\n",
    "            imout = image.copy()\n",
    "            counter = 0\n",
    "            falsecounter = 0\n",
    "            flag = 0\n",
    "            fflag = 0\n",
    "            bflag = 0\n",
    "            for e,result in enumerate(ssresults):\n",
    "                if e < 2000 and flag == 0:\n",
    "                    for gtval in gtvalues:\n",
    "                        x,y,w,h = result\n",
    "                        iou = get_iou(gtval,{\"x1\":x,\"x2\":x+w,\"y1\":y,\"y2\":y+h})\n",
    "                        if counter < 30:\n",
    "                            if iou > 0.70:\n",
    "                                timage = imout[y:y+h,x:x+w]\n",
    "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                                train_images.append(resized)\n",
    "                                train_labels.append(1)\n",
    "                                counter += 1\n",
    "                        else :\n",
    "                            fflag =1\n",
    "                        if falsecounter <30:\n",
    "                            if iou < 0.3:\n",
    "                                timage = imout[y:y+h,x:x+w]\n",
    "                                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                                train_images.append(resized)\n",
    "                                train_labels.append(0)\n",
    "                                falsecounter += 1\n",
    "                        else :\n",
    "                            bflag = 1\n",
    "                    if fflag == 1 and bflag == 1:\n",
    "                        #print(\"inside\")\n",
    "                        flag = 1\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        #print(\"error in \"+filename)\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bd3y8hdFWnkJ"
   },
   "outputs": [],
   "source": [
    "X_new = np.array(train_images)\n",
    "y_new = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFRdrCPwWnkK"
   },
   "outputs": [],
   "source": [
    "for layers in (vggmodel.layers)[:15]:\n",
    "    layers.trainable = False\n",
    "    \n",
    "X = vggmodel.layers[-2].output\n",
    "predictions = Dense(2, activation=\"softmax\")(X)\n",
    "model_final = Model(inputs = vggmodel.input, outputs = predictions)\n",
    "opt = Adam(lr=0.0001)\n",
    "model_final.compile(loss = keras.losses.categorical_crossentropy, optimizer = opt, metrics=[\"accuracy\"])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNsVWEWfWnkK"
   },
   "source": [
    "Doing one hot encoding for the data set, using the LabelBinarizer() and using it in a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbcMNNcWWnkL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "class MyLabelBinarizer(LabelBinarizer):\n",
    "    def transform(self, y):\n",
    "        Y = super().transform(y)\n",
    "        if self.y_type_ == 'binary':\n",
    "            return np.hstack((Y, 1-Y))\n",
    "        else:\n",
    "            return Y\n",
    "    def inverse_transform(self, Y, threshold=None):\n",
    "        if self.y_type_ == 'binary':\n",
    "            return super().inverse_transform(Y[:, 0], threshold)\n",
    "        else:\n",
    "            return super().inverse_transform(Y, threshold)\n",
    "lenc = MyLabelBinarizer()\n",
    "Y =  lenc.fit_transform(y_new)\n",
    "X_train, X_test , y_train, y_test = train_test_split(X_new,Y,test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1MT7--xWnkL"
   },
   "source": [
    "Defining the data generators and doing data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxOq8EXOWnkL"
   },
   "outputs": [],
   "source": [
    "traingen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "traindata = traingen.flow(x=X_train, y=y_train)\n",
    "testgen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "testdata = testgen.flow(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTqxjTSDWnkL"
   },
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qaP3AMwWnkM"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"rcnn_vgg16.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')\n",
    "hist = model_final.fit(traindata, steps_per_epoch=len(X_train)/batch_size, epochs=epochs, validation_data=testdata, validation_steps=len(X_test)/batch_size, callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3giPKetWnkM"
   },
   "source": [
    "Evaluating the model by seeing how it does on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaIFC2x_dDO6"
   },
   "outputs": [],
   "source": [
    "_, train_acc = model_final.evaluate(X_train, y_train, verbose=0)\n",
    "_, test_acc = model_final.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8RTHHAPWnkM"
   },
   "outputs": [],
   "source": [
    "z=0\n",
    "for e,i in enumerate(os.listdir(image_path)):\n",
    "    if i.startswith(\"4\"):\n",
    "        z += 1\n",
    "        img = cv2.imread(os.path.join(image_path,i))\n",
    "        ss.setBaseImage(img)\n",
    "        ss.switchToSelectiveSearchFast()\n",
    "        ssresults = ss.process()\n",
    "        imout = img.copy()\n",
    "        for e,result in enumerate(ssresults):\n",
    "            if e < 2000:\n",
    "                x,y,w,h = result\n",
    "                timage = imout[y:y+h,x:x+w]\n",
    "                resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                img = np.expand_dims(resized, axis=0)\n",
    "                out= model_final.predict(img)\n",
    "                if out[0][0] > 0.70:\n",
    "                    cv2.rectangle(imout, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(imout)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "RCNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
